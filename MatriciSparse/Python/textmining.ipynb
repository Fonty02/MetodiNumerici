{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.sparse as sparse\n",
    "import scipy.sparse.linalg as spla\n",
    "import sklearn\n",
    "import sklearn.feature_extraction\n",
    "from gensim.parsing.preprocessing import remove_stopwords, stem_text #prova su jupyter\n",
    "\n",
    "np.set_printoptions(suppress=True) # questo comando impedisce a numpy di stampare numeri molto piccoli in notazione scientifica\n",
    "vectorizer=sklearn.feature_extraction.text.CountVectorizer(min_df=1) # min_df=1 significa che consideriamo tutte le parole che compaiono almeno una volta (default=1)\n",
    "documenti=['How to','ciao ciao ciao','sadkmdj jsadnd sad', 'skiivjjivd',' a d f c ciao cakee cake computer science']\n",
    "X=vectorizer.fit_transform(documenti)\n",
    "A=X.T\n",
    "\n",
    "L=[]\n",
    "for i in range(len(documenti)):\n",
    "    L.append(remove_stopwords(documenti[i]))\n",
    "L_final=[]\n",
    "for i in range(len(documenti)):\n",
    "    L_final.append(stem_text(L[i]))\n",
    "print(L_final)\n",
    "\n",
    "Y=vectorizer.fit_transform(L_final).toarray()\n",
    "query1=['cake computer']\n",
    "query_stemmed=stem_text(query1[0])\n",
    "query1=[]\n",
    "query1.append(query_stemmed)\n",
    "query1=vectorizer.transform(query1).toarray()\n",
    "\n",
    "(m,n)=A.shape\n",
    "eu=np.array(np.zeros(n))\n",
    "for i in range(n):\n",
    "    eu[i]=np.linalg.norm(A[:,i],2) #calcolo la norma 2 di ogni colonna di A\n",
    "\n",
    "An=np.dot(A,np.diag(1/eu)) #normalizzo le colonne di A\n",
    "\n",
    "#eventualmente per calcolare la correlazione lineare devo trasformarmi in una distribuzione normale (vedi appunti). Qui per semplicit√† abbiamo solo normalizzato con la norma 2\n",
    "\n",
    "coseni=np.dot(An.T,query1.T)/np.linalg.norm(query1,2) #calcolo il coseno tra le colonne di An e la query\n",
    "print(coseni)\n",
    "\n",
    "\n",
    "#VEDIAMO CON LA SVD\n",
    "\n",
    "U,s,Vt=np.linalg.svd(An,full_matrices=True)\n",
    "r=np.linalg.matrix_rank(An)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(s)\n",
    "\n",
    "#creo usando solo 4 valori singolari\n",
    "S=s[0:4]*np.eye(4,4)\n",
    "An4=np.dot(U[:,0:4],np.dot(S,Vt[0:4,:]))\n",
    "coseni4=np.dot(An4.T,query1.T)/np.linalg.norm(query1,2) #calcolo il coseno tra le colonne di An e la query\n",
    "#vediamo come alcuni valori dei coseni salgono. Queste info aggiuntive POTREBBERO essere utili\n",
    "\n",
    "As=sparse.csr_matrix(An)\n",
    "u4,s4,v4t=sp.sparse.linalg.svds(As,k=4,solver='arpack') #arpack usa la bidiagonalizzazione di Lanczos\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svdA=TruncatedSVD(n_components=4,n_iter=1,random_state=42)\n",
    "svdA.fit(An)\n",
    "\n",
    "valori_singolari=svdA.singular_values_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
